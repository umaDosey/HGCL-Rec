{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.75732595  0.77317103 -0.03280656  0.97792386  0.90806082 -0.61106498\n",
      "  0.83590159 -1.02373287  0.54207553 -1.05760535]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# サンプル数\n",
    "num_samples = 10\n",
    "\n",
    "# Gumbel(0, 1)分布からサンプリング\n",
    "gumbel_samples = np.random.gumbel(loc=0, scale=1, size=num_samples)\n",
    "\n",
    "# 結果の表示\n",
    "print(gumbel_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.7588801244480392\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_similarity(xi, hj, weight_vectors):\n",
    "    # xiとhjを重みベクトルで重みづけ\n",
    "    weighted_xi = [w * xi for w in weight_vectors]\n",
    "    weighted_hj = [w * hj for w in weight_vectors]\n",
    "    \n",
    "    # 重みづけされたベクトル同士のコサイン類似度を計算\n",
    "    similarities = [cosine_similarity([wx], [wh])[0, 0] for wx, wh in zip(weighted_xi, weighted_hj)]\n",
    "    \n",
    "    # 類似度の平均を計算\n",
    "    average_similarity = np.mean(similarities)\n",
    "    \n",
    "    return average_similarity\n",
    "\n",
    "# 例として、ランダムなベクトルや重みベクトルを用意\n",
    "xi = np.random.rand(300)  # 300次元のランダムベクトル\n",
    "hj = np.random.rand(300)  # 300次元のランダムベクトル\n",
    "weight_vectors = [np.random.rand(300) for _ in range(5)]  # 5つの重みベクトル\n",
    "\n",
    "# 類似度の計算\n",
    "similarity = compute_similarity(xi, hj, weight_vectors)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Similarity: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Similarity Matrix S: (5, 10, 8)\n",
      "Similarity Matrix S:\n",
      "[[[0.72170549 0.74466962 0.75442993 0.72926793 0.75885162 0.75623697\n",
      "   0.80247929 0.78059372]\n",
      "  [0.73857753 0.74844628 0.72165759 0.72486635 0.76337127 0.76733505\n",
      "   0.74073947 0.73448043]\n",
      "  [0.70795111 0.75271518 0.73152537 0.75341771 0.75134152 0.77857834\n",
      "   0.70983922 0.73691625]\n",
      "  [0.76044966 0.77483683 0.72183097 0.75290315 0.77020697 0.78366312\n",
      "   0.73705193 0.76074919]\n",
      "  [0.74415637 0.71345751 0.74872243 0.73935775 0.77531874 0.78291042\n",
      "   0.71653041 0.76597643]\n",
      "  [0.77440768 0.77445729 0.76461356 0.7458649  0.77508956 0.786261\n",
      "   0.74440628 0.74481199]\n",
      "  [0.76818575 0.71881975 0.73955285 0.74026594 0.74948334 0.80143742\n",
      "   0.76796341 0.72506399]\n",
      "  [0.77468941 0.72203262 0.72865093 0.70897984 0.72401692 0.73613322\n",
      "   0.73207191 0.76889932]\n",
      "  [0.75283302 0.71608174 0.73182622 0.70053793 0.72593673 0.79652392\n",
      "   0.74752991 0.74013667]\n",
      "  [0.74863717 0.74721637 0.73385667 0.71802429 0.75398225 0.78287615\n",
      "   0.74316728 0.75348444]]\n",
      "\n",
      " [[0.68746219 0.74583563 0.76426035 0.72377139 0.73941656 0.73982312\n",
      "   0.76296133 0.74097284]\n",
      "  [0.75214655 0.73180291 0.75510135 0.76999801 0.74011925 0.76132862\n",
      "   0.77818695 0.7514022 ]\n",
      "  [0.71733303 0.72531952 0.75519966 0.74418129 0.70976598 0.73972419\n",
      "   0.73089032 0.76411023]\n",
      "  [0.7723708  0.76893222 0.74889408 0.7573649  0.74697016 0.76427314\n",
      "   0.74239677 0.78077565]\n",
      "  [0.7657322  0.73179454 0.75367603 0.75971539 0.72962057 0.78780659\n",
      "   0.73954876 0.75941434]\n",
      "  [0.77191691 0.71468485 0.78887311 0.73954026 0.73115152 0.769154\n",
      "   0.76615113 0.74516804]\n",
      "  [0.75627061 0.728036   0.7892577  0.75278622 0.72715888 0.80771872\n",
      "   0.77216869 0.7566895 ]\n",
      "  [0.77992568 0.70953461 0.7543631  0.74145334 0.69157514 0.73445378\n",
      "   0.75343996 0.76906352]\n",
      "  [0.71510821 0.73026156 0.75596844 0.73641982 0.70833814 0.77734053\n",
      "   0.72133935 0.7256334 ]\n",
      "  [0.73978638 0.75294564 0.76853325 0.78009732 0.7706174  0.76938467\n",
      "   0.75052396 0.79394017]]\n",
      "\n",
      " [[0.7248289  0.73863039 0.74112043 0.72114612 0.72081847 0.74097234\n",
      "   0.80638023 0.77192249]\n",
      "  [0.7468886  0.75156739 0.74627122 0.75996346 0.72480651 0.76092248\n",
      "   0.76490877 0.77538166]\n",
      "  [0.72990769 0.72868469 0.74250202 0.75962431 0.75064809 0.77272943\n",
      "   0.74796001 0.72581667]\n",
      "  [0.78053076 0.77274009 0.73105689 0.73023168 0.7675186  0.7482872\n",
      "   0.77553987 0.78118107]\n",
      "  [0.7369308  0.69368228 0.723852   0.73342251 0.72539372 0.75736472\n",
      "   0.72239087 0.70523276]\n",
      "  [0.7861923  0.75508888 0.77341857 0.74071771 0.73920774 0.78059279\n",
      "   0.77407818 0.72244945]\n",
      "  [0.7712474  0.70411788 0.7526451  0.75238877 0.73766461 0.78926902\n",
      "   0.76707808 0.76255871]\n",
      "  [0.80257807 0.72116986 0.76640025 0.74726283 0.69643942 0.74410535\n",
      "   0.75520329 0.77010262]\n",
      "  [0.75237834 0.71390829 0.74842971 0.74379372 0.75330984 0.77475637\n",
      "   0.74508474 0.75189734]\n",
      "  [0.73960377 0.71453926 0.73218612 0.77208309 0.72131556 0.74958633\n",
      "   0.72068507 0.75593763]]\n",
      "\n",
      " [[0.73968457 0.75317216 0.76479256 0.72237041 0.74942687 0.7766759\n",
      "   0.79512278 0.77648752]\n",
      "  [0.76611859 0.74880628 0.72593041 0.74501011 0.76671958 0.77740375\n",
      "   0.75170187 0.77710863]\n",
      "  [0.72763567 0.73398081 0.74490408 0.7456009  0.75244035 0.77974281\n",
      "   0.72340634 0.77234178]\n",
      "  [0.78414896 0.78223863 0.74473615 0.7618388  0.76268741 0.79728964\n",
      "   0.7728665  0.79901602]\n",
      "  [0.75506141 0.7247712  0.78383169 0.72650896 0.75250222 0.76206181\n",
      "   0.71327792 0.75742623]\n",
      "  [0.78393096 0.73677215 0.7909387  0.72570242 0.75206629 0.77034618\n",
      "   0.77855781 0.75205463]\n",
      "  [0.77485973 0.7489408  0.78584595 0.75408044 0.76229527 0.79605383\n",
      "   0.78845344 0.76680872]\n",
      "  [0.78816075 0.70602167 0.75984221 0.73633502 0.71469718 0.76406256\n",
      "   0.77092303 0.78099598]\n",
      "  [0.73641896 0.73185277 0.76926974 0.7240389  0.74537659 0.78828713\n",
      "   0.75365078 0.76617084]\n",
      "  [0.77387294 0.76665214 0.74808347 0.73425207 0.76280406 0.80189353\n",
      "   0.76381911 0.81016845]]\n",
      "\n",
      " [[0.71200416 0.775932   0.74912852 0.74014338 0.75379945 0.76819838\n",
      "   0.79615501 0.76814286]\n",
      "  [0.75369171 0.75368836 0.73341514 0.73446474 0.75608329 0.74546536\n",
      "   0.77512038 0.76205815]\n",
      "  [0.73212304 0.73180533 0.73914187 0.73908014 0.72864766 0.77395037\n",
      "   0.76299655 0.78668963]\n",
      "  [0.7681785  0.72967274 0.72380991 0.76480641 0.76691787 0.7806496\n",
      "   0.79396367 0.78077112]\n",
      "  [0.74678332 0.71464024 0.75733179 0.75253544 0.75121702 0.75631152\n",
      "   0.72643896 0.73723821]\n",
      "  [0.76847855 0.74526881 0.76507184 0.7625902  0.73052166 0.74869872\n",
      "   0.763663   0.75786798]\n",
      "  [0.75101471 0.72708533 0.79876134 0.77547275 0.75980486 0.77594827\n",
      "   0.80649004 0.7484497 ]\n",
      "  [0.79184548 0.73243211 0.73159366 0.7348944  0.71534819 0.73680747\n",
      "   0.77118613 0.78385221]\n",
      "  [0.71166259 0.73972774 0.74680708 0.74269544 0.73527605 0.75698454\n",
      "   0.77941911 0.77172903]\n",
      "  [0.76713676 0.75424258 0.70746647 0.73175204 0.74569188 0.76786761\n",
      "   0.75500214 0.78224067]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_similarity_matrix(X, H, weight_matrices):\n",
    "    # XとHを各重みベクトルで要素ごとに重みづけ\n",
    "    weighted_X = weight_matrices[:, None, :] * X[None, :, :]\n",
    "    weighted_H = weight_matrices[:, None, :] * H[None, :, :]\n",
    "\n",
    "    # 重みづけされたベクトル同士のコサイン類似度を計算\n",
    "    numerator = np.sum(weighted_X[:, :, None, :] * weighted_H[:, None, :, :], axis=-1)\n",
    "    denominator = np.linalg.norm(weighted_X, axis=-1)[:, :, None] * np.linalg.norm(weighted_H, axis=-1)[:, None, :]\n",
    "\n",
    "    # 類似度の計算\n",
    "    similarities = numerator / denominator\n",
    "\n",
    "    return similarities\n",
    "\n",
    "# 例として、ランダムな行列XとH、および5つのランダムな300次元の重みベクトルを用意\n",
    "X = np.random.rand(10, 300)  # 10行300列のランダム行列\n",
    "H = np.random.rand(8, 300)   # 8行300列のランダム行列\n",
    "weight_matrices = np.random.rand(5, 300)  # 5つのランダムな300次元の重みベクトル\n",
    "\n",
    "# 類似度の計算\n",
    "similarities = compute_similarity_matrix(X, H, weight_matrices)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Shape of Similarity Matrix S: {similarities.shape}\")\n",
    "# print(f\"Similarity Matrix S:\\n{similarities}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Similarity Matrix S: (2000, 2500)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_similarity_matrix(X, H, weight_matrices):\n",
    "    # XとHを各重みベクトルで要素ごとに重みづけ\n",
    "    weighted_X = weight_matrices[:, None, :] * X[None, :, :]\n",
    "    weighted_H = weight_matrices[:, None, :] * H[None, :, :]\n",
    "\n",
    "    # 重みづけされたベクトル同士のコサイン類似度を計算\n",
    "    numerator = np.sum(weighted_X[:, :, None, :] * weighted_H[:, None, :, :], axis=-1)\n",
    "    denominator = np.linalg.norm(weighted_X, axis=-1)[:, :, None] * np.linalg.norm(weighted_H, axis=-1)[:, None, :]\n",
    "\n",
    "    # 類似度の計算\n",
    "    similarities = numerator / denominator\n",
    "\n",
    "    # 最後に類似度の平均をとる\n",
    "    average_similarity = np.mean(similarities, axis=(0))\n",
    "\n",
    "    return average_similarity\n",
    "\n",
    "# 例として、ランダムな行列XとH、および5つのランダムな300次元の重みベクトルを用意\n",
    "X = np.random.rand(2000, 300)  # 10行300列のランダム行列\n",
    "H = np.random.rand(2500, 300)   # 8行300列のランダム行列\n",
    "weight_matrices = np.random.rand(5, 300)  # 5つのランダムな300次元の重みベクトル\n",
    "\n",
    "# 類似度の計算\n",
    "similarities = compute_similarity_matrix(X, H, weight_matrices)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Shape of Similarity Matrix S: {similarities.shape}\")\n",
    "# print(f\"Similarity Matrix S:\\n{similarities}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Similarity Matrix S: (2000, 2500)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_similarity_matrix(X, H, weight_matrices):\n",
    "    # XとHを各重みベクトルで要素ごとに重みづけ\n",
    "    # weighted_X = weight_matrices[:, None, :] * X[None, :, :]\n",
    "    # weighted_H = weight_matrices[:, None, :] * H[None, :, :]\n",
    "\n",
    "    # ベクトル同士のコサイン類似度を計算\n",
    "    similarities = cosine_similarity(X, H)\n",
    "\n",
    "    # 形状を元に戻す\n",
    "    # similarities = similarities.reshape((weight_matrices.shape[0], X.shape[0], H.shape[0]))\n",
    "\n",
    "    # 最後に類似度の平均をとる\n",
    "    # average_similarity = np.mean(similarities, axis=(0))\n",
    "\n",
    "    return similarities\n",
    "\n",
    "# 例として、ランダムな行列XとH、および5つのランダムな50次元の重みベクトルを用意\n",
    "X = np.random.rand(2000, 50)  # 2000行50列のランダム行列\n",
    "H = np.random.rand(2500, 50)   # 2500行50列のランダム行列\n",
    "weight_matrices = np.random.rand(5, 50)  # 5つのランダムな50次元の重みベクトル\n",
    "\n",
    "# 類似度の計算\n",
    "similarities = compute_similarity_matrix(X, H, weight_matrices)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Shape of Similarity Matrix S: {similarities.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Similarity Matrix S:\n",
      " [[0.76476584 0.79407114 0.7332108  ... 0.74834192 0.76767119 0.71058369]\n",
      " [0.81380124 0.72782257 0.74553753 ... 0.66817478 0.76552082 0.75656667]\n",
      " [0.70943869 0.73726766 0.73730553 ... 0.70611923 0.75846901 0.74852535]\n",
      " ...\n",
      " [0.64859318 0.68419978 0.68054361 ... 0.67688171 0.74624207 0.72642998]\n",
      " [0.7266724  0.72969489 0.66719796 ... 0.74771545 0.81942909 0.81118321]\n",
      " [0.69930834 0.66311968 0.69231891 ... 0.71608449 0.80742114 0.78125681]]\n",
      "\n",
      "Threshold Padd: 0.2\n",
      "\n",
      "Sparse Residual Hypergraph Structure ∆H:\n",
      " [[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sparsify_residual_hypergraph(S, padd):\n",
    "    # Sij ∈ top(S, padd) なるインデックスを取得\n",
    "    top_indices = np.argsort(S, axis=None)[-int(padd * S.size):]\n",
    "    top_indices = np.unravel_index(top_indices, S.shape)\n",
    "\n",
    "    # ∆H を初期化し、条件に基づいて更新\n",
    "    delta_H = np.zeros_like(S)\n",
    "    delta_H[top_indices] = 1\n",
    "\n",
    "    return delta_H\n",
    "\n",
    "# 例として、ランダムな類似度行列Sとpaddの設定\n",
    "S = similarities  # 10行8列のランダムな類似度行列\n",
    "padd = 0.2  # paddの設定（例として0.2）\n",
    "\n",
    "# ∆Hの計算\n",
    "delta_H = sparsify_residual_hypergraph(S, padd)\n",
    "\n",
    "# 結果の表示\n",
    "print(\"Original Similarity Matrix S:\\n\", S)\n",
    "print(f\"\\nThreshold Padd: {padd}\")\n",
    "print(\"\\nSparse Residual Hypergraph Structure ∆H:\\n\", delta_H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Similarity Matrix S:\n",
      " [[0.2421557  0.20255876 0.65636414 0.6671348  0.60567918 0.1765118\n",
      "  0.3147378  0.16139861]\n",
      " [0.17441088 0.89969018 0.16910072 0.68212474 0.92522437 0.68532618\n",
      "  0.99748686 0.96217281]\n",
      " [0.94575924 0.70822651 0.11457328 0.61319642 0.85544617 0.29846297\n",
      "  0.37044649 0.67759247]\n",
      " [0.99479312 0.89649799 0.39318324 0.79119313 0.4622452  0.88426665\n",
      "  0.5111331  0.8580635 ]\n",
      " [0.91654219 0.23857365 0.65611565 0.5059415  0.00264665 0.46880323\n",
      "  0.78470667 0.34716833]\n",
      " [0.80985455 0.4661992  0.00484452 0.12463024 0.3704152  0.90950536\n",
      "  0.5296558  0.23818284]\n",
      " [0.11726684 0.55926656 0.04204345 0.98386363 0.497373   0.9865708\n",
      "  0.74685577 0.40121339]\n",
      " [0.25898339 0.68524307 0.49095259 0.29452661 0.46433413 0.17256475\n",
      "  0.62244914 0.12207616]\n",
      " [0.62165386 0.42693681 0.67921164 0.28604127 0.6689141  0.43442613\n",
      "  0.46079725 0.01667868]\n",
      " [0.19865221 0.64475424 0.05372382 0.58164901 0.61102353 0.93958653\n",
      "  0.22329474 0.55417785]]\n",
      "\n",
      "Original Hypergraph Structure H:\n",
      " [[1 0 0 1 0 1 1 1]\n",
      " [0 1 1 1 0 1 1 0]\n",
      " [0 0 0 1 1 0 1 0]\n",
      " [0 0 1 0 0 1 1 0]\n",
      " [0 0 0 0 1 0 1 1]\n",
      " [1 0 0 0 1 0 1 0]\n",
      " [0 1 1 0 1 0 1 0]\n",
      " [1 0 0 0 1 0 0 0]\n",
      " [1 0 1 0 1 0 0 1]\n",
      " [0 0 0 1 0 0 0 1]]\n",
      "\n",
      "Threshold Padd: 0.2\n",
      "\n",
      "Sparse Residual Hypergraph Structure ∆H:\n",
      " [[0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 1]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sparsify_residual_hypergraph(S, padd, original_connections):\n",
    "    # Sij ∈ top(S, padd) なるインデックスを取得\n",
    "    top_indices = np.argsort(S, axis=None)[-int(padd * S.size):]\n",
    "    top_indices = np.unravel_index(top_indices, S.shape)\n",
    "\n",
    "    # ∆H を初期化し、条件に基づいて更新\n",
    "    delta_H = np.zeros_like(S)\n",
    "    delta_H[top_indices] = 1\n",
    "\n",
    "    # Hij = 0 かつ Sij ∈ top(S, padd) の場合、∆Hij = 1 とする\n",
    "    delta_H = np.where((original_connections == 0) & (delta_H == 1), 1, 0)\n",
    "\n",
    "    return delta_H\n",
    "\n",
    "# 例として、ランダムな類似度行列Sとランダムな0または1の要素を持つ10×8のHijを生成\n",
    "S = np.random.rand(10, 8)  # 10行8列のランダムな類似度行列\n",
    "original_connections = np.random.randint(2, size=(10, 8))  # 0または1のランダムな10×8の行列\n",
    "padd = 0.2  # paddの設定（例として0.2）\n",
    "\n",
    "# ∆Hの計算\n",
    "delta_H = sparsify_residual_hypergraph(S, padd, original_connections)\n",
    "\n",
    "# 結果の表示\n",
    "print(\"Original Similarity Matrix S:\\n\", S)\n",
    "print(\"\\nOriginal Hypergraph Structure H:\\n\", original_connections)\n",
    "print(f\"\\nThreshold Padd: {padd}\")\n",
    "print(\"\\nSparse Residual Hypergraph Structure ∆H:\\n\", delta_H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zvij:\n",
      "[1.]\n",
      "Mvij:\n",
      "[0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4008/1695196027.py:17: RuntimeWarning: divide by zero encountered in log\n",
      "  Mvij = 1 / (1 + np.exp((np.log(Zvij) - np.log(1 - Zvij) + epsilon_0 - epsilon_1) / temperature))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gumbel_softmax(logits, temperature=1.0):\n",
    "    gumbel_noise = -np.log(-np.log(np.random.rand(*logits.shape)))\n",
    "    softmax_output = np.exp((logits + gumbel_noise) / temperature) / np.exp((logits + gumbel_noise) / temperature).sum(axis=-1, keepdims=True)\n",
    "    return softmax_output\n",
    "\n",
    "def calculate_Zvij(xi, hj, mlp_weights):\n",
    "    mlp_input = np.concatenate([xi, hj], axis=-1)\n",
    "    mlp_output = np.dot(mlp_input, mlp_weights)\n",
    "    Zvij = gumbel_softmax(mlp_output)\n",
    "    return Zvij\n",
    "\n",
    "def calculate_Mvij(Zvij, temperature=1.0):\n",
    "    epsilon_0 = np.random.gumbel(0, 1, size=Zvij.shape)\n",
    "    epsilon_1 = np.random.gumbel(0, 1, size=Zvij.shape)\n",
    "    Mvij = 1 / (1 + np.exp((np.log(Zvij) - np.log(1 - Zvij) + epsilon_0 - epsilon_1) / temperature))\n",
    "    return Mvij\n",
    "\n",
    "# 例として、ランダムなベクトルxiとhj、およびMLPの重み行列を生成\n",
    "xi = np.random.rand(300)  # 300次元のランダムベクトル\n",
    "hj = np.random.rand(300)  # 300次元のランダムベクトル\n",
    "mlp_weights = np.random.rand(600, 1)  # 600次元のMLPの重み行列\n",
    "\n",
    "# 温度パラメータを設定\n",
    "temperature = 0.2\n",
    "\n",
    "# Zvijの計算\n",
    "Zvij = calculate_Zvij(xi, hj, mlp_weights)\n",
    "\n",
    "# Mvijの計算\n",
    "Mvij = calculate_Mvij(Zvij, temperature)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Zvij:\\n{Zvij}\")\n",
    "print(f\"Mvij:\\n{Mvij}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_new:\n",
      "[[0.96445748 1.30585797 0.28657013 0.24923662 0.02591257 0.71320091\n",
      "  1.28757729 0.33768663]\n",
      " [0.42369893 0.12740756 0.52117965 0.78376985 0.60402181 0.55914571\n",
      "  0.62499286 0.59065779]\n",
      " [0.09207111 0.33495748 0.56581788 0.21769254 0.78619303 0.10581853\n",
      "  0.10708234 0.37364129]\n",
      " [1.67036608 1.26062884 1.75906878 0.28679184 0.45771533 0.51584465\n",
      "  0.21838073 0.53661267]\n",
      " [1.51567815 1.23864762 1.22415186 0.00278174 0.21432357 0.67107776\n",
      "  0.05513312 0.14404983]\n",
      " [0.63870756 0.83103434 0.65956204 0.73923454 0.86439712 0.21339498\n",
      "  1.29116929 0.8161523 ]\n",
      " [0.14283508 0.20834146 0.82687531 0.16683651 0.19224239 0.85408526\n",
      "  0.10322303 0.22927661]\n",
      " [1.07293443 0.76347887 0.65527581 0.54470772 0.64435455 0.42497833\n",
      "  1.35028573 0.92752549]\n",
      " [0.9084389  0.08474892 0.4110021  0.37247067 0.773224   1.16584815\n",
      "  0.82015976 1.0333787 ]\n",
      " [0.47398926 0.82100538 0.53047788 0.08738916 0.4942123  0.3897364\n",
      "  0.12575733 0.12113216]]\n"
     ]
    }
   ],
   "source": [
    "def calculate_H(H, Mvij, delta_H, E, N):\n",
    "    I = np.zeros_like(H)\n",
    "    E_indices, N_indices = np.arange(E), np.arange(N)\n",
    "    I[E_indices[:, None] + N, N_indices] = 1\n",
    "\n",
    "    H_new = Mvij * (H + delta_H) + I\n",
    "    return H_new\n",
    "\n",
    "# 例として、ランダムな行列Hとdelta_H、およびMvijの生成\n",
    "H = np.random.rand(10, 8)  # 10行8列のランダム行列\n",
    "delta_H = np.random.rand(10, 8)  # 10行8列のランダム行列\n",
    "Mvij = np.random.rand(10, 8)  # 10行8列のランダム行列\n",
    "\n",
    "# EとNの設定\n",
    "E, N = 2, 3\n",
    "\n",
    "# Hの更新\n",
    "H_new = calculate_H(H, Mvij, delta_H, E, N)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"H_new:\\n{H_new}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_new:\n",
      "[[1.56492902 1.85431791 1.07616423 1.95805188 1.86272267 1.09377319\n",
      "  2.22468643 1.05130149]\n",
      " [1.01156971 1.52810572 1.21187493 1.69515704 1.31195575 1.17757233\n",
      "  2.01788712 1.09616008]\n",
      " [2.00577002 1.02739378 2.03905871 2.02660339 1.21063368 1.67712188\n",
      "  1.346081   1.98594817]\n",
      " [2.04810269 1.64077177 1.25431905 1.56990265 1.22057609 1.89136443\n",
      "  2.25970183 1.38667153]\n",
      " [1.21107334 1.86300574 1.56806958 1.31636537 1.99120691 1.20289878\n",
      "  1.84513632 1.11571523]\n",
      " [2.21274747 1.5592926  2.05096561 1.45537709 1.38859047 2.03562157\n",
      "  1.54588927 1.50098461]\n",
      " [1.08543563 1.46811884 1.12247394 1.08265358 1.78358113 1.23636892\n",
      "  2.87208491 1.44544649]\n",
      " [1.54719545 1.73863236 1.62706027 2.25565749 1.07340746 1.20831759\n",
      "  1.64514037 2.2482767 ]\n",
      " [1.03404841 2.04345167 2.00913307 1.32309871 2.36003909 1.56170271\n",
      "  1.32482801 2.26259344]\n",
      " [1.38030138 1.74823099 1.80705933 1.05357653 1.08369177 1.39470101\n",
      "  1.35839157 1.26414162]]\n"
     ]
    }
   ],
   "source": [
    "def calculate_H(H, Mvij, delta_H, E, N):\n",
    "    I = np.zeros_like(H)\n",
    "    for i in range(E):\n",
    "        for j in range(N):\n",
    "            I[i, j] = 1\n",
    "\n",
    "    H_new = Mvij * (H + delta_H) + I\n",
    "    return H_new\n",
    "\n",
    "# 例として、ランダムな行列Hとdelta_H、およびMvijの生成\n",
    "H = np.random.rand(10, 8)  # 10行8列のランダム行列\n",
    "delta_H = np.random.rand(10, 8)  # 10行8列のランダム行列\n",
    "Mvij = np.random.rand(10, 8)  # 10行8列のランダム行列\n",
    "\n",
    "# EとNの設定\n",
    "E, N = 10, 8\n",
    "\n",
    "# Hの更新\n",
    "H_new = calculate_H(H, Mvij, delta_H, E, N)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"H_new:\\n{H_new}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_new:\n",
      "[[2.7463719  2.20239422 1.01098245 1.82606944 1.47774737 2.13861596\n",
      "  1.39679147 1.25488556]\n",
      " [1.22350403 1.42879374 2.26016834 1.91738141 1.30556311 1.41453999\n",
      "  1.27779713 1.20984263]\n",
      " [1.68311041 1.33422429 1.61771529 1.02500259 1.28896227 1.07494704\n",
      "  1.49164208 1.68191914]\n",
      " [1.16030403 1.44647525 1.00349612 2.22058119 1.4160494  1.40908851\n",
      "  2.28138698 1.24235118]\n",
      " [1.83205772 1.11461808 1.27673644 1.66434728 1.27484331 1.58472204\n",
      "  1.63604206 1.04271904]\n",
      " [1.45840548 1.68806704 2.24843978 1.35336909 2.18404445 1.64800245\n",
      "  1.29807795 1.78949428]\n",
      " [1.89504402 2.01810762 1.20502243 1.53251522 1.36589333 1.26688802\n",
      "  1.41588017 1.12813974]\n",
      " [1.21379372 1.12405439 1.2432784  1.8927342  1.00663197 1.5082828\n",
      "  1.36673756 1.36690904]\n",
      " [1.34193673 1.68653323 1.07813592 1.41288252 1.22938995 2.20699863\n",
      "  2.04181185 1.8570783 ]\n",
      " [1.44665177 1.35871689 1.69628392 1.02017949 1.12801185 2.50172909\n",
      "  1.25430014 1.28969888]]\n",
      "Shape of H_new: (10, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_H(H, Mvij, delta_H, E, N):\n",
    "    I = np.zeros_like(H)\n",
    "    for i in range(E):\n",
    "        for j in range(N):\n",
    "            I[i, j] = 1\n",
    "\n",
    "    H_new = Mvij * (H + delta_H) + I\n",
    "    return H_new\n",
    "\n",
    "# 例として、ランダムな行列Hとdelta_H、およびMvijの生成\n",
    "H = np.random.rand(10, 8)  # 10行8列のランダム行列\n",
    "delta_H = np.random.rand(10, 8)  # 10行8列のランダム行列\n",
    "Mvij = np.random.rand(10, 8)  # 10行8列のランダム行列\n",
    "\n",
    "# EとNの設定\n",
    "E, N = 10, 8\n",
    "\n",
    "# Hの更新\n",
    "H_new = calculate_H(H, Mvij, delta_H, E, N)\n",
    "\n",
    "# 結果とサイズの表示\n",
    "print(f\"H_new:\\n{H_new}\")\n",
    "print(f\"Shape of H_new: {H_new.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [39], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Zvijの計算\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m Zvij \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_Zvij_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Mvijの計算\u001b[39;00m\n\u001b[1;32m     32\u001b[0m Mvij \u001b[38;5;241m=\u001b[39m calculate_Mvij_batch(Zvij, temperature)\n",
      "Cell \u001b[0;32mIn [39], line 9\u001b[0m, in \u001b[0;36mcalculate_Zvij_batch\u001b[0;34m(X, H, mlp_weights)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_Zvij_batch\u001b[39m(X, H, mlp_weights):\n\u001b[0;32m----> 9\u001b[0m     mlp_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([X[:, \u001b[38;5;28;01mNone\u001b[39;00m, :], \u001b[43mH\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m     mlp_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(mlp_input, mlp_weights)\n\u001b[1;32m     11\u001b[0m     Zvij \u001b[38;5;241m=\u001b[39m gumbel_softmax_batch(mlp_output)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gumbel_softmax_batch(logits, temperature=1.0):\n",
    "    gumbel_noise = -np.log(-np.log(np.random.rand(*logits.shape)))\n",
    "    softmax_output = np.exp((logits + gumbel_noise) / temperature) / np.exp((logits + gumbel_noise) / temperature).sum(axis=-1, keepdims=True)\n",
    "    return softmax_output\n",
    "\n",
    "def calculate_Zvij_batch(X, H, mlp_weights):\n",
    "    mlp_input = np.concatenate([X[:, None, :], H[:, :, None, :]], axis=-1)\n",
    "    mlp_output = np.dot(mlp_input, mlp_weights)\n",
    "    Zvij = gumbel_softmax_batch(mlp_output)\n",
    "    return Zvij\n",
    "\n",
    "def calculate_Mvij_batch(Zvij, temperature=1.0):\n",
    "    epsilon_0 = np.random.gumbel(0, 1, size=Zvij.shape)\n",
    "    epsilon_1 = np.random.gumbel(0, 1, size=Zvij.shape)\n",
    "    Mvij = 1 / (1 + np.exp((np.log(Zvij) - np.log(1 - Zvij) + epsilon_0 - epsilon_1) / temperature))\n",
    "    return Mvij\n",
    "\n",
    "# 例として、ランダムな行列XとH、およびMLPの重み行列を生成\n",
    "X = np.random.rand(100, 300)  # 100行300列のランダム行列\n",
    "H = np.random.rand(80, 300)   # 80行300列のランダム行列\n",
    "mlp_weights = np.random.rand(600, 1)  # 600次元のMLPの重み行列\n",
    "\n",
    "# 温度パラメータを設定\n",
    "temperature = 0.2\n",
    "\n",
    "# Zvijの計算\n",
    "Zvij = calculate_Zvij_batch(X, H, mlp_weights)\n",
    "\n",
    "# Mvijの計算\n",
    "Mvij = calculate_Mvij_batch(Zvij, temperature)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Shape of Zvij: {Zvij.shape}\")\n",
    "print(f\"Shape of Mvij: {Mvij.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 100 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [40], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Zvijの計算\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m Zvij \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_Zvij_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Mvijの計算\u001b[39;00m\n\u001b[1;32m     32\u001b[0m Mvij \u001b[38;5;241m=\u001b[39m calculate_Mvij_batch(Zvij, temperature)\n",
      "Cell \u001b[0;32mIn [40], line 9\u001b[0m, in \u001b[0;36mcalculate_Zvij_batch\u001b[0;34m(X, H, mlp_weights)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_Zvij_batch\u001b[39m(X, H, mlp_weights):\n\u001b[0;32m----> 9\u001b[0m     mlp_input \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     mlp_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(mlp_input, mlp_weights)\n\u001b[1;32m     11\u001b[0m     Zvij \u001b[38;5;241m=\u001b[39m gumbel_softmax_batch(mlp_output)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 100 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gumbel_softmax_batch(logits, temperature=1.0):\n",
    "    gumbel_noise = -np.log(-np.log(np.random.rand(*logits.shape)))\n",
    "    softmax_output = np.exp((logits + gumbel_noise) / temperature) / np.exp((logits + gumbel_noise) / temperature).sum(axis=-1, keepdims=True)\n",
    "    return softmax_output\n",
    "\n",
    "def calculate_Zvij_batch(X, H, mlp_weights):\n",
    "    mlp_input = np.concatenate([X[:, None, :], H[None, :, :]], axis=-1)\n",
    "    mlp_output = np.dot(mlp_input, mlp_weights)\n",
    "    Zvij = gumbel_softmax_batch(mlp_output)\n",
    "    return Zvij\n",
    "\n",
    "def calculate_Mvij_batch(Zvij, temperature=1.0):\n",
    "    epsilon_0 = np.random.gumbel(0, 1, size=Zvij.shape)\n",
    "    epsilon_1 = np.random.gumbel(0, 1, size=Zvij.shape)\n",
    "    Mvij = 1 / (1 + np.exp((np.log(Zvij) - np.log(1 - Zvij) + epsilon_0 - epsilon_1) / temperature))\n",
    "    return Mvij\n",
    "\n",
    "# 例として、ランダムな行列XとH、およびMLPの重み行列を生成\n",
    "X = np.random.rand(100, 300)  # 100行300列のランダム行列\n",
    "H = np.random.rand(80, 300)   # 80行300列のランダム行列\n",
    "mlp_weights = np.random.rand(600, 1)  # 600次元のMLPの重み行列\n",
    "\n",
    "# 温度パラメータを設定\n",
    "temperature = 0.2\n",
    "\n",
    "# Zvijの計算\n",
    "Zvij = calculate_Zvij_batch(X, H, mlp_weights)\n",
    "\n",
    "# Mvijの計算\n",
    "Mvij = calculate_Mvij_batch(Zvij, temperature)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Shape of Zvij: {Zvij.shape}\")\n",
    "print(f\"Shape of Mvij: {Mvij.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 100 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [43], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Zv と Mv の計算\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m Zv, Mv \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_Zv_and_Mv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# 結果の表示\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZv shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mZv\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [43], line 10\u001b[0m, in \u001b[0;36mcalculate_Zv_and_Mv\u001b[0;34m(X, H, mlp_weights, temperature)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_Zv_and_Mv\u001b[39m(X, H, mlp_weights, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# 行列 X と H を結合\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     concatenated_input \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# MLP で Zv を計算\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     mlp_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(concatenated_input, mlp_weights)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 100 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gumbel_softmax(logits, temperature=1.0):\n",
    "    gumbel_noise = -np.log(-np.log(np.random.rand(*logits.shape)))\n",
    "    softmax_output = np.exp((logits + gumbel_noise) / temperature) / np.exp((logits + gumbel_noise) / temperature).sum(axis=-1, keepdims=True)\n",
    "    return softmax_output\n",
    "\n",
    "def calculate_Zv_and_Mv(X, H, mlp_weights, temperature=1.0):\n",
    "    # 行列 X と H を結合\n",
    "    concatenated_input = np.concatenate([X[:, None, :], H[None, :, :]], axis=-1)\n",
    "\n",
    "    # MLP で Zv を計算\n",
    "    mlp_output = np.dot(concatenated_input, mlp_weights)\n",
    "    Zv = gumbel_softmax(mlp_output, temperature)\n",
    "\n",
    "    # Gumbel Softmax で Mv を計算\n",
    "    epsilon_0 = np.random.gumbel(0, 1, size=Zv.shape)\n",
    "    epsilon_1 = np.random.gumbel(0, 1, size=Zv.shape)\n",
    "    Mv = 1 / (1 + np.exp((np.log(Zv) - np.log(1 - Zv) + epsilon_0 - epsilon_1) / temperature))\n",
    "\n",
    "    return Zv, Mv\n",
    "\n",
    "# 例として、ランダムな行列 X と H、および MLP の重み行列を生成\n",
    "X = np.random.rand(100, 300)  # 100行300列のランダム行列\n",
    "H = np.random.rand(80, 300)   # 80行300列のランダム行列\n",
    "mlp_weights = np.random.rand(600, 1)  # 600次元のMLPの重み行列\n",
    "\n",
    "# 温度パラメータを設定\n",
    "temperature = 0.2\n",
    "\n",
    "# Zv と Mv の計算\n",
    "Zv, Mv = calculate_Zv_and_Mv(X, H, mlp_weights, temperature)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Zv shape: {Zv.shape}\")\n",
    "print(f\"Mv shape: {Mv.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmnentation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Similarity Matrix S: (2000, 2500)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torchmetrics.functional import pairwise_cosine_similarity\n",
    "\n",
    "def compute_similarity_matrix(X, H, weight_matrices):\n",
    "    # XとHを各重みベクトルで要素ごとに重みづけ\n",
    "    # weighted_X = weight_matrices[:, None, :] * X[None, :, :]\n",
    "    # weighted_H = weight_matrices[:, None, :] * H[None, :, :]\n",
    "\n",
    "    # ベクトル同士のコサイン類似度を計算\n",
    "    similarities = cosine_similarity(X, H)\n",
    "\n",
    "    # 形状を元に戻す\n",
    "    # similarities = similarities.reshape((weight_matrices.shape[0], X.shape[0], H.shape[0]))\n",
    "\n",
    "    # 最後に類似度の平均をとる\n",
    "    # average_similarity = np.mean(similarities, axis=(0))\n",
    "\n",
    "    return similarities\n",
    "\n",
    "# 例として、ランダムな行列XとH、および5つのランダムな50次元の重みベクトルを用意\n",
    "X = np.random.rand(2000, 50)  # 2000行50列のランダム行列\n",
    "H = np.random.rand(2500, 50)   # 2500行50列のランダム行列\n",
    "weight_matrices = np.random.rand(5, 50)  # 5つのランダムな50次元の重みベクトル\n",
    "\n",
    "# 類似度の計算\n",
    "similarities = compute_similarity_matrix(X, H, weight_matrices)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Shape of Similarity Matrix S: {similarities.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Similarity Matrix S: (2000, 2500)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchmetrics.functional import pairwise_cosine_similarity\n",
    "\n",
    "def compute_similarity_matrix(X, H, weight_matrices):\n",
    "    # NumPy配列をPyTorchのテンソルに変換\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    H_tensor = torch.tensor(H, dtype=torch.float32)\n",
    "\n",
    "    # ベクトル同士のコサイン類似度を計算\n",
    "    similarities = pairwise_cosine_similarity(X_tensor, H_tensor)\n",
    "\n",
    "    # 形状を元に戻す\n",
    "    # similarities = similarities.reshape((weight_matrices.shape[0], X.shape[0], H.shape[0]))\n",
    "\n",
    "    # 最後に類似度の平均をとる\n",
    "    # average_similarity = torch.mean(similarities, dim=0)\n",
    "\n",
    "    return similarities.numpy()\n",
    "\n",
    "# 例として、ランダムな行列XとH、および5つのランダムな50次元の重みベクトルを用意\n",
    "X = np.random.rand(2000, 50)\n",
    "H = np.random.rand(2500, 50)\n",
    "weight_matrices = np.random.rand(5, 50)\n",
    "\n",
    "# 類似度の計算\n",
    "similarities = compute_similarity_matrix(X, H, weight_matrices)\n",
    "\n",
    "# 結果の表示\n",
    "print(f\"Shape of Similarity Matrix S: {similarities.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Similarity Matrix S:\n",
      " [[0.79142661 0.71178958 0.76653226 ... 0.78592776 0.64937173 0.81739442]\n",
      " [0.79544696 0.73278497 0.71575509 ... 0.70464985 0.71698694 0.72681481]\n",
      " [0.76365017 0.77337271 0.80723859 ... 0.81292286 0.73311453 0.78494889]\n",
      " ...\n",
      " [0.76567529 0.75905927 0.84670424 ... 0.7839514  0.71618988 0.77462489]\n",
      " [0.79695826 0.74925907 0.76949224 ... 0.82465223 0.78466913 0.76559352]\n",
      " [0.79914746 0.76578298 0.79661495 ... 0.77113744 0.67891072 0.7949222 ]]\n",
      "\n",
      "Threshold Padd: 0.2\n",
      "\n",
      "Sparse Residual Hypergraph Structure ∆H:\n",
      " [[1. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sparsify_residual_hypergraph(S, padd):\n",
    "    # Sij ∈ top(S, padd) なるインデックスを取得\n",
    "    top_indices = np.argsort(S, axis=None)[-int(padd * S.size):]\n",
    "    top_indices = np.unravel_index(top_indices, S.shape)\n",
    "\n",
    "    # ∆H を初期化し、条件に基づいて更新\n",
    "    delta_H = np.zeros_like(S)\n",
    "    delta_H[top_indices] = 1\n",
    "\n",
    "    return delta_H\n",
    "\n",
    "# 例として、ランダムな類似度行列Sとpaddの設定\n",
    "S = similarities  # 10行8列のランダムな類似度行列\n",
    "padd = 0.2  # paddの設定（例として0.2）\n",
    "\n",
    "# ∆Hの計算\n",
    "delta_H = sparsify_residual_hypergraph(S, padd)\n",
    "\n",
    "# 結果の表示\n",
    "print(\"Original Similarity Matrix S:\\n\", S)\n",
    "print(f\"\\nThreshold Padd: {padd}\")\n",
    "print(\"\\nSparse Residual Hypergraph Structure ∆H:\\n\", delta_H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Binary Matrix H:\n",
      " [[0 1 0 ... 0 1 0]\n",
      " [1 0 0 ... 1 1 1]\n",
      " [1 0 1 ... 1 0 0]\n",
      " ...\n",
      " [1 0 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [0 0 0 ... 1 0 0]]\n",
      "\n",
      "Sparse Residual Hypergraph Structure ∆H:\n",
      " [[1. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 1.]]\n",
      "\n",
      "Updated Binary Matrix H_hat:\n",
      " [[1. 1. 0. ... 0. 1. 1.]\n",
      " [2. 0. 0. ... 1. 1. 1.]\n",
      " [1. 0. 2. ... 2. 0. 0.]\n",
      " ...\n",
      " [1. 0. 2. ... 1. 1. 1.]\n",
      " [2. 1. 1. ... 2. 1. 1.]\n",
      " [1. 0. 1. ... 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sparsify_residual_hypergraph(S, padd):\n",
    "    top_indices = np.argsort(S, axis=None)[-int(padd * S.size):]\n",
    "    top_indices = np.unravel_index(top_indices, S.shape)\n",
    "    delta_H = np.zeros_like(S)\n",
    "    delta_H[top_indices] = 1\n",
    "    return delta_H\n",
    "\n",
    "def create_H_hat(original_H, delta_H):\n",
    "    H_hat = original_H + delta_H\n",
    "    return H_hat\n",
    "\n",
    "# 例として、ランダムな類似度行列 S と padd の設定\n",
    "S = similarities  # 10行8列のランダムな類似度行列\n",
    "padd = 0.2  # paddの設定（例として0.2）\n",
    "\n",
    "# ∆Hの計算\n",
    "delta_H = sparsify_residual_hypergraph(S, padd)\n",
    "\n",
    "# 例として、ランダムなバイナリ行列 original_H の生成\n",
    "original_H = np.random.randint(2, size=(2000, 2500))\n",
    "\n",
    "# H_hatの計算\n",
    "H_hat = create_H_hat(original_H, delta_H)\n",
    "\n",
    "# 結果の表示\n",
    "print(\"Original Binary Matrix H:\\n\", original_H)\n",
    "print(\"\\nSparse Residual Hypergraph Structure ∆H:\\n\", delta_H)\n",
    "print(\"\\nUpdated Binary Matrix H_hat:\\n\", H_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Binary Matrix H:\n",
      " [[1 0 1 ... 0 0 1]\n",
      " [1 1 1 ... 1 0 0]\n",
      " [1 0 0 ... 1 0 1]\n",
      " ...\n",
      " [0 1 1 ... 0 0 1]\n",
      " [0 0 0 ... 1 1 1]\n",
      " [1 1 1 ... 1 0 0]]\n",
      "\n",
      "Sparse Residual Hypergraph Structure ∆H:\n",
      " [[1. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 1.]]\n",
      "\n",
      "Sparse Residual Hypergraph Structure ∇H:\n",
      " [[0. 1. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "\n",
      "Updated Binary Matrix H_hat:\n",
      " [[ 2. -1.  1. ...  0. -1.  2.]\n",
      " [ 2.  1.  1. ...  0.  0.  0.]\n",
      " [ 1.  0.  1. ...  2.  0.  1.]\n",
      " ...\n",
      " [ 0.  1.  2. ...  0.  0.  1.]\n",
      " [ 1.  0.  0. ...  2.  1.  1.]\n",
      " [ 2.  1.  2. ...  1. -1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def nabla_residual_hypergraph(S, padd):\n",
    "    bottom_indices = np.argsort(S, axis=None)[:int(padd * S.size)]\n",
    "    bottom_indices = np.unravel_index(bottom_indices, S.shape)\n",
    "    delta_H = np.zeros_like(S)\n",
    "    delta_H[bottom_indices] = 1\n",
    "    return delta_H\n",
    "import numpy as np\n",
    "\n",
    "def delta_residual_hypergraph(S, padd):\n",
    "    top_indices = np.argsort(S, axis=None)[-int(padd * S.size):]\n",
    "    top_indices = np.unravel_index(top_indices, S.shape)\n",
    "    delta_H = np.zeros_like(S)\n",
    "    delta_H[top_indices] = 1\n",
    "    return delta_H\n",
    "\n",
    "def create_H_hat(original_H, delta_H, nabla_H):\n",
    "    H_hat = original_H + delta_H - nabla_H\n",
    "    return H_hat\n",
    "\n",
    "# 例として、ランダムな類似度行列 S と padd の設定\n",
    "S = similarities  # 10行8列のランダムな類似度行列\n",
    "padd = 0.2  # paddの設定（例として0.2）\n",
    "\n",
    "# ∆Hの計算\n",
    "delta_H = delta_residual_hypergraph(S, padd)\n",
    "nabla_H = nabla_residual_hypergraph(S, padd)\n",
    "\n",
    "# 例として、ランダムなバイナリ行列 original_H の生成\n",
    "original_H = np.random.randint(2, size=(2000, 2500))\n",
    "\n",
    "# H_hatの計算\n",
    "H_hat = create_H_hat(original_H, delta_H, nabla_H)\n",
    "\n",
    "# 結果の表示\n",
    "print(\"Original Binary Matrix H:\\n\", original_H)\n",
    "print(\"\\nSparse Residual Hypergraph Structure ∆H:\\n\", delta_H)\n",
    "print(\"\\nSparse Residual Hypergraph Structure ∇H:\\n\", nabla_H)\n",
    "print(\"\\nUpdated Binary Matrix H_hat:\\n\", H_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Binary Matrix H:\n",
      " [[1 1 1 ... 0 1 1]\n",
      " [1 0 1 ... 0 1 0]\n",
      " [1 1 1 ... 0 1 1]\n",
      " ...\n",
      " [1 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [1 1 1 ... 1 0 1]]\n",
      "\n",
      "Sparse Residual Hypergraph Structure ∆H:\n",
      " [[1. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 1. ... 0. 0. 1.]]\n",
      "\n",
      "Sparse Residual Hypergraph Structure ∇H:\n",
      " [[0. 1. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "\n",
      "Updated Binary Matrix H_hat:\n",
      " [[1. 0. 1. ... 0. 0. 1.]\n",
      " [1. 0. 1. ... 0. 1. 0.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 1.]\n",
      " [1. 1. 1. ... 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nabla_residual_hypergraph(S, padd):\n",
    "    bottom_indices = np.argsort(S, axis=None)[:int(padd * S.size)]\n",
    "    bottom_indices = np.unravel_index(bottom_indices, S.shape)\n",
    "    nabla_H = np.zeros_like(S)\n",
    "    nabla_H[bottom_indices] = 1\n",
    "    return nabla_H\n",
    "\n",
    "def delta_residual_hypergraph(S, padd):\n",
    "    top_indices = np.argsort(S, axis=None)[-int(padd * S.size):]\n",
    "    top_indices = np.unravel_index(top_indices, S.shape)\n",
    "    delta_H = np.zeros_like(S)\n",
    "    delta_H[top_indices] = 1\n",
    "    return delta_H\n",
    "\n",
    "def create_H_hat(original_H, delta_H, nabla_H):\n",
    "    H_hat = np.clip(original_H + delta_H - nabla_H, 0, 1)  # 0以下の値を0に、1以上の値を1にクリップ\n",
    "    return H_hat\n",
    "\n",
    "# 例として、ランダムな類似度行列 S と padd の設定\n",
    "S = similarities  # 10行8列のランダムな類似度行列\n",
    "padd = 0.2  # paddの設定（例として0.2）\n",
    "\n",
    "# ∆Hと∇Hの計算\n",
    "delta_H = delta_residual_hypergraph(S, padd)\n",
    "nabla_H = nabla_residual_hypergraph(S, padd)\n",
    "\n",
    "# 例として、ランダムなバイナリ行列 original_H の生成\n",
    "original_H = np.random.randint(2, size=(2000, 2500))\n",
    "\n",
    "# H_hatの計算\n",
    "H_hat = create_H_hat(original_H, delta_H, nabla_H)\n",
    "\n",
    "# 結果の表示\n",
    "print(\"Original Binary Matrix H:\\n\", original_H)\n",
    "print(\"\\nSparse Residual Hypergraph Structure ∆H:\\n\", delta_H)\n",
    "print(\"\\nSparse Residual Hypergraph Structure ∇H:\\n\", nabla_H)\n",
    "print(\"\\nUpdated Binary Matrix H_hat:\\n\", H_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2159, 0.5742, 0.0042, 0.5853, 0.0000],\n",
      "        [0.2530, 0.2083, 0.5865, 1.1397, 0.8767],\n",
      "        [0.2459, 0.1843, 0.3081, 1.2387, 0.2236],\n",
      "        [0.6141, 0.6159, 0.0499, 0.0774, 0.0000],\n",
      "        [0.8702, 0.1417, 0.7778, 0.5947, 0.8906]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4008/427284596.py:16: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  top_indices = (top_indices // S.size(1), top_indices % S.size(1))\n",
      "/tmp/ipykernel_4008/427284596.py:8: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bottom_indices = (bottom_indices // S.size(1), bottom_indices % S.size(1))\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "\n",
    "class YourClassName:\n",
    "    def LearnedHyperGraph(self, H, S):\n",
    "        def nabla_residual_hypergraph(S, padd):\n",
    "            values, indices = t.sort(S.view(-1))\n",
    "            bottom_indices = indices[:int(padd * S.numel())]\n",
    "            bottom_indices = (bottom_indices // S.size(1), bottom_indices % S.size(1))\n",
    "            nabla_H = t.zeros_like(S)\n",
    "            nabla_H[bottom_indices] = 1\n",
    "            return nabla_H\n",
    "\n",
    "        def delta_residual_hypergraph(S, padd):\n",
    "            values, indices = t.sort(S.view(-1))\n",
    "            top_indices = indices[-int(padd * S.numel()):]\n",
    "            top_indices = (top_indices // S.size(1), top_indices % S.size(1))\n",
    "            delta_H = t.zeros_like(S)\n",
    "            delta_H[top_indices] = 1\n",
    "            return delta_H\n",
    "\n",
    "        def create_H_hat(original_H, delta_H, nabla_H):\n",
    "            H_hat = t.clamp(original_H + delta_H - nabla_H, 0, float('inf'))  # 0以下の値を0に、1以上の値を1にクリップ\n",
    "            return H_hat\n",
    "\n",
    "        padd = 0.1  # paddの設定（例として0.2）\n",
    "\n",
    "        # ∆Hと∇Hの計算\n",
    "        delta_H = delta_residual_hypergraph(S, padd)\n",
    "        nabla_H = nabla_residual_hypergraph(S, padd)\n",
    "        H_hat = create_H_hat(H, delta_H, nabla_H)\n",
    "        Learned_H, _ = self.Laplcian_matrix(H_hat)\n",
    "\n",
    "        return Learned_H\n",
    "\n",
    "    def Laplcian_matrix(self, H_hat):\n",
    "        # ラプラシアン行列の計算関数があると仮定します\n",
    "        # 実際のラプラシアン行列計算コードに置き換えてください\n",
    "        # 元のコードの2番目の返り値はこの関数では使用されていません\n",
    "        # したがって、それに合わせて調整する必要があります\n",
    "        # この関数がない場合は、要件に基づいて実装する必要があります\n",
    "        # 例示のため、単にH_hatを返すだけのプレースホルダーとしています\n",
    "        return H_hat, None\n",
    "\n",
    "# ランダムなデータ生成\n",
    "H = t.rand((5, 5))\n",
    "S = t.rand((5, 5))\n",
    "\n",
    "# YourClassNameのインスタンスを作成\n",
    "your_instance = YourClassName()\n",
    "\n",
    "# LearnedHyperGraphメソッドを呼び出し\n",
    "result = your_instance.LearnedHyperGraph(H, S)\n",
    "\n",
    "# 結果を表示\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
